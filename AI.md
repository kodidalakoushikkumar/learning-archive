# COMPLETE ARTIFICIAL INTELLIGENCE TREE

```
ARTIFICIAL INTELLIGENCE
â”‚
â”œâ”€â”€ 1) Symbolic / Classical AI
â”‚     â”œâ”€â”€ Rule-Based Systems
â”‚     â”œâ”€â”€ Expert Systems
â”‚     â”œâ”€â”€ Knowledge Representation
â”‚     â”œâ”€â”€ Logic Programming
â”‚     â””â”€â”€ Search Algorithms
â”‚
â”œâ”€â”€ 2) Machine Learning
â”‚     â”œâ”€â”€ Supervised Learning
â”‚     â”‚      â”œâ”€â”€ Regression
â”‚     â”‚      â””â”€â”€ Classification
â”‚     â”‚
â”‚     â”œâ”€â”€ Unsupervised Learning
â”‚     â”‚      â”œâ”€â”€ Clustering
â”‚     â”‚      â”œâ”€â”€ Dimensionality Reduction
â”‚     â”‚      â””â”€â”€ Association Rules
â”‚     â”‚
â”‚     â”œâ”€â”€ Semi-Supervised Learning
â”‚     â”œâ”€â”€ Self-Supervised Learning
â”‚     â”œâ”€â”€ Reinforcement Learning
â”‚     â”‚      â”œâ”€â”€ Q-Learning
â”‚     â”‚      â”œâ”€â”€ Policy Learning
â”‚     â”‚      â””â”€â”€ Deep Reinforcement Learning
â”‚     â”‚
â”‚     â””â”€â”€ Deep Learning
â”‚            â”œâ”€â”€ Neural Networks (ANN)
â”‚            â”‚      â”œâ”€â”€ Feedforward Networks
â”‚            â”‚      â”œâ”€â”€ Backpropagation
â”‚            â”‚      â””â”€â”€ Optimization Algorithms
â”‚            â”‚
â”‚            â”œâ”€â”€ CNN (Vision Models)
â”‚            â”‚      â”œâ”€â”€ Object Detection
â”‚            â”‚      â”œâ”€â”€ Image Segmentation
â”‚            â”‚      â””â”€â”€ Face Recognition
â”‚            â”‚
â”‚            â”œâ”€â”€ RNN (Sequence Models)
â”‚            â”‚      â”œâ”€â”€ LSTM
â”‚            â”‚      â””â”€â”€ GRU
â”‚            â”‚
â”‚            â”œâ”€â”€ Generative Models
â”‚            â”‚      â”œâ”€â”€ Autoencoders
â”‚            â”‚      â”œâ”€â”€ VAEs
â”‚            â”‚      â”œâ”€â”€ GANs
â”‚            â”‚      â””â”€â”€ Diffusion Models
â”‚            â”‚
â”‚            â””â”€â”€ Transformers
â”‚                   â”œâ”€â”€ Encoder Models (BERT)
â”‚                   â”œâ”€â”€ Decoder Models (GPT)
â”‚                   â”œâ”€â”€ Encoder-Decoder (T5)
â”‚                   â””â”€â”€ Large Language Models (LLMs)
â”‚
â”œâ”€â”€ 3) Natural Language Processing
â”‚     â”œâ”€â”€ Text Classification
â”‚     â”œâ”€â”€ Named Entity Recognition
â”‚     â”œâ”€â”€ Machine Translation
â”‚     â”œâ”€â”€ Question Answering
â”‚     â”œâ”€â”€ Summarization
â”‚     â””â”€â”€ Chatbots / Assistants
â”‚
â”œâ”€â”€ 4) Computer Vision
â”‚     â”œâ”€â”€ Image Classification
â”‚     â”œâ”€â”€ Object Detection
â”‚     â”œâ”€â”€ Tracking
â”‚     â”œâ”€â”€ OCR (text from image)
â”‚     â””â”€â”€ Video Analysis
â”‚
â”œâ”€â”€ 5) Speech & Audio AI
â”‚     â”œâ”€â”€ Speech Recognition
â”‚     â”œâ”€â”€ Text-to-Speech
â”‚     â”œâ”€â”€ Speaker Identification
â”‚     â””â”€â”€ Sound Classification
â”‚
â”œâ”€â”€ 6) Robotics
â”‚     â”œâ”€â”€ Motion Planning
â”‚     â”œâ”€â”€ SLAM (mapping & navigation)
â”‚     â”œâ”€â”€ Manipulation
â”‚     â””â”€â”€ Autonomous Driving
â”‚
â”œâ”€â”€ 7) Planning & Optimization
â”‚     â”œâ”€â”€ Path Finding
â”‚     â”œâ”€â”€ Scheduling
â”‚     â”œâ”€â”€ Resource Allocation
â”‚     â””â”€â”€ Game Playing
â”‚
â”œâ”€â”€ 8) Multi-Agent Systems
â”‚     â”œâ”€â”€ Swarm Intelligence
â”‚     â”œâ”€â”€ Distributed AI
â”‚     â””â”€â”€ Cooperative Agents
â”‚
â””â”€â”€ 9) Human-AI Interaction
      â”œâ”€â”€ Recommendation Systems
      â”œâ”€â”€ Personal Assistants
      â””â”€â”€ Human Feedback Learning

```

# 1) Supervised Learning
You give the machine: **Input + Correct Output (answers)**
It learns the mapping.  `x â†’ y email â†’ spam photo â†’ cat house features â†’ price`
Think: teacher supervising a student.
## A) Regression (predict a number)
Output is continuous value.
Examples:
- House price prediction
- Temperature forecasting
- Sales prediction
- Stock value estimation
### How it learns
Finds mathematical relationship:  `price = 2*(rooms) + 500*(area) + noise`
Algorithms:
- Linear Regression
- Polynomial Regression
- Ridge / Lasso
- Random Forest Regressor
ðŸ‘‰ Used heavily in business analytics & forecasting
## B) Classification (predict a category)
Output is a label.
Examples:
- Spam / Not Spam
- Fraud / Legit
- Disease / Healthy
- Churn / Not churn
Algorithms:
- Logistic Regression
- Decision Tree
- Random Forest
- SVM
- k-Nearest Neighbor
- Naive Bayes
ðŸ‘‰ Most common real-world ML task
# 2) Unsupervised Learning
You give **only data â€” no answers**
Machine discovers structure itself.
Think: grouping unknown objects in a box.
## A) Clustering (group similar items)
Example:  
Customers grouped by buying behavior
`Group A â†’ rich customers Group B â†’ discount seekers Group C â†’ rare buyers`
Algorithms:
- K-Means
- Hierarchical Clustering
- DBSCAN
Used in:
- Marketing segmentation
- Fraud anomaly detection
- Social network analysis
## B) Dimensionality Reduction (compress data)
High-feature data â†’ fewer features while keeping information.
Example:   1000 features â†’ 10 meaningful features
Algorithms:
- PCA
- t-SNE
- UMAP
Used in:
- Visualization
- Speeding up models
- Noise removal
## C) Association Rules (pattern relationships)
Finds â€œpeople who buy X also buy Yâ€
Example:  `Beer â†’ Diapers Laptop â†’ Mouse Phone â†’ Case`
Algorithm:
- Apriori
- FP-Growth
Used in recommender systems.
# 3) Semi-Supervised Learning
Small labeled data + large unlabeled data.
Because labeling is expensive.
Example:   1000 labeled medical scans + 1 million unlabeled scans.
Used in:
- Medical AI
- Industrial inspection
# 4) Self-Supervised Learning (Modern AI magic)
Model creates its own labels.
Example:   Hide word in sentence â†’ prdict missing word
`"The cat is on the ___"`
This is how modern language models learn before training.
Used by models from OpenAI and Google.
# 5) Reinforcement Learning
Learning by **reward and punishment**
Agent interacts with environment.
`action â†’ reward â†’ learn`
Example:  
Robot walking:
- falls â†’ bad reward
- stable â†’ good reward    
Used in:
- Game AI
- Robotics
- Traffic control
- Trading systems
## Types
### Value-based
Learn value of each action  
(eg: Q-Learning)
### Policy-based
Learn best behavior directly
### Deep Reinforcement Learning
Neural networks + RL  
Used in advanced game AIs.
# 6) Deep Learning (subset of ML)
When dataset becomes huge â†’ traditional ML fails.
So we use neural networks.
## Inside Deep Learning

- Neural Networks â†’ general patterns
- CNN â†’ images
- RNN â†’ sequences/time
- Transformers â†’ language/context
- Generative Models â†’ create data

# SIMPLE MEMORY MAP

|Problem|ML Type|
|---|---|
|Predict number|Regression|
|Predict category|Classification|
|Find hidden groups|Clustering|
|Compress data|Dimensionality Reduction|
|Recommend items|Association Rules|
|Learn from rewards|Reinforcement Learning|
|Learn from massive raw data|Deep Learning|

# One-line intuition

> Supervised = learn from teacher  
> Unsupervised = discover patterns  
> Reinforcement = learn from experience  
> Deep Learning = learn complex patterns automatically

## 1) Artificial Intelligence (AI)
**Goal:** Make machines behave intelligently (like humans)
This does NOT always mean learning.
Examples:
- Rule-based chatbot: â€œIf user says hello â†’ reply helloâ€
- Chess engine calculating best move
- Face unlock in phone
- Spam detection
ðŸ‘‰ AI is the **entire field** â€” biggest umbrella.
So:
> All ML is AI  
> But not all AI is ML
## 2) Machine Learning (ML)
Machines **learn patterns from data instead of hardcoding rules**
Instead of:  `if email contains "lottery" -> spam`
We do:  `Show 1 million emails â†’ machine learns what spam looks like`
Examples:
- Netflix recommendations
- Credit card fraud detection
- Stock prediction
- Voice recognition
ðŸ‘‰ ML = subset of AI that learns from data
## 3) Deep Learning (DL)
A special type of ML using **layers of math neurons**
Normal ML: Uses human-chosen features
Deep Learning:  Finds features automatically
Example:   You teach computer â€œcatâ€
Traditional ML: You manually tell: ears shape, tail, eyes
Deep Learning:  Show 10 million images â†’ it figures everything

Used in:
- Speech recognition
- Image recognition
- Chatbots
- Self driving
ðŸ‘‰ DL = subset of ML
## 4) Neural Networks
The **algorithm inside Deep Learning**
Inspired by human brain neurons: `Input â†’ Hidden Layers â†’ Output`
Each layer learns patterns:
- Layer 1: edges
- Layer 5: shapes
- Layer 20: faces
- Layer 100: emotions
So:

> Neural Networks are the ENGINE  
> Deep Learning is the CAR

## 5) Transformers (Big Breakthrough â€” 2017)
A new neural network design from  
Google research paper **â€œAttention Is All You Needâ€**
They understand relationships between words instead of sequence memory.
Old models:  read word by word
Transformers:   read entire sentence at once
Thatâ€™s why modern AI understands context.
## 6) GPT (Generative Pre-trained Transformer)
Created by OpenAI
GPT is a **type of transformer model specialized in language generation**
What it does:   Predict next word repeatedly
Example:   `"I drank coffee because I was..." â†’ tired`
After trillions of predictions â†’ becomes ChatGPT.
So:

> GPT is NOT AI  
> GPT is NOT ML  
> GPT is NOT Deep Learning

It is:   One specific model inside Deep Learning